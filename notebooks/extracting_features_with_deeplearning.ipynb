{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rich\n",
    "%load_ext ensurewd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from torchvision import models\n",
    "\n",
    "from utils.config import get_conf\n",
    "from utils.features_extract import (\n",
    "    get_images_features,\n",
    "    get_transformers,\n",
    ")\n",
    "from utils.func import get_path_list\n",
    "from utils.models import VGG16Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'features_matrix'\u001b[0m: \u001b[32m' '\u001b[0m\u001b[1m}\u001b[0m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path to dataset\n",
    "TRAIN_PATH = Path('../data/raw/histopathologic-cancer-detection/train/')\n",
    "TEST_PATH = Path('../data/raw/histopathologic-cancer-detection/test/')\n",
    "\n",
    "FEATURES_MATRIX_CSV = Path(\n",
    "    '../data/raw/histopathologic-cancer-detection/feature_matrix_train.csv',\n",
    ")\n",
    "\n",
    "TRAIN_LABELS_PATH_CSV = Path(\n",
    "    '../data/raw/histopathologic-cancer-detection/train_labels.csv'\n",
    ")\n",
    "\n",
    "CONF_PATH = Path('../data/conf.toml')\n",
    "\n",
    "dataset_conf = get_conf(conf_path=CONF_PATH)\n",
    "\n",
    "histopathologic_cancer_conf = dataset_conf['histopatological_cancer_detection']\n",
    "histopathologic_cancer_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test path list\n",
    "\n",
    "train_images_path_list = get_path_list(TRAIN_PATH)\n",
    "test_images_path_list = get_path_list(TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a custom model to extract images features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smrenato/repo/eda_histopathologic_cancer_detect/.venv/lib64/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# getting model\n",
    "vgg16 = models.vgg16(weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building our custom model\n",
    "device = 'cuda'  # cpu\n",
    "features_extractor_model = VGG16Extractor(vgg16).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mCompose\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mCenterCrop\u001b[0m\u001b[1m(\u001b[0m\u001b[33msize\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m32\u001b[0m, \u001b[1;36m32\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1;35mResize\u001b[0m\u001b[1m(\u001b[0m\u001b[33msize\u001b[0m=\u001b[1;36m448\u001b[0m, \u001b[33minterpolation\u001b[0m=\u001b[35mbilinear\u001b[0m, \u001b[33mmax_size\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mantialias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "    \u001b[1;35mToTensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformer\n",
    "transformeres = get_transformers()\n",
    "transformeres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1m(\u001b[0m\n",
       "    \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m0.2443\u001b[0m, \u001b[1;36m-0.2892\u001b[0m, \u001b[1;36m-2.0232\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m-1.1370\u001b[0m,  \u001b[1;36m0.0349\u001b[0m, \u001b[1;36m-1.2414\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
       "       \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m, \u001b[1;36m4096\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of feature from train dataset\n",
    "\n",
    "img_features = get_images_features(\n",
    "    features_extractor_model,\n",
    "    train_images_path_list[:10],  # using just 10, because it'll take a while\n",
    "    transformeres,\n",
    ")\n",
    "img_features[0], img_features[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
